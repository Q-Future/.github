# üëÅÔ∏è‚Äçüó®Ô∏è Low-level Visual Perception in the Foundation Model Era

_üîñAiming at next-era cornerstone research_

‚≠ê _Low-level Visual Perception | Multi-Modality Large Language Models | Visual Quality Assessment_
#### üìñMain Projects

- ‚ë£**Co-Instruct**: [Homepage](https://co-instruct.github.io/), [Repo](https://github.com/Q-Future/Co-Instruct), [Demo](https://q-future-co-instruct.hf.space/). Open-ended visual quality comparer (up to 4 images), low-level visual assistant, an improved version of ‚ë°**Q-Instruct [CVPR 2024]**.

- ‚ë¢**Q-Align**: [Homepage](https://q-align.github.io/), [Repo](https://github.com/Q-Future/Q-Align), [Demo](https://q-future-onealign.hf.space/). A unified visual scorer for images and videos, via text-instructed alignment on multi-modality foundation models; can efficiently fine-tune to more datasets with stable good performance. State-of-the-art on IQA, VQA, and IAA.

- ‚ë°**Q-Instruct [CVPR 2024]**: [Homepage](https://q-future.github.io/Q-Instruct), [Repo](https://github.com/Q-Future/Q-Instruct),  [200K Dataset](https://huggingface.co/datasets/teowu/Q-Instruct), [Technical Report](https://q-future.github.io/Q-Instruct/fig/Q_Instruct_v0_1_preview.pdf) A large-scale instruction tuning dataset to improve low-level perceptual abilities of foundation models.

- ‚ë†**Q-Bench+ [ICLR2024, Spotlight]**: [Homepage](https://q-future.github.io/Q-Bench/), [Repo](https://github.com/Q-Future/Q-Bench), [Data-Single](https://github.com/Q-Future/Q-Bench/releases/tag/v1.0.1.1014datarelease), [Data-Pair](https://huggingface.co/zhangzicheng/q-bench2), [Preprint](https://arxiv.org/abs/2309.14181) The first low-level benchmark for foundation models on low-level vision.

#### üñãÔ∏èExtension Projects

- **Q-Boost**: [Homepage](https://q-future.github.io/Q-Instruct/boost_qa) A discussion on boosting the IQA performance for non-specially-IQA-aligned MLLMs.

- **[Pending]Chinese-Q-Bench/Ë¥®Ë°°**: [Homepage](https://q-future.github.io/Chinese-Q-Bench/), [Repo](https://github.com/Q-Future/Chinese-Q-Bench) The first attempt to test multi-lingual abilities on low-level vision.



Maintained by [Teo Wu](https://github.com/teowu)@Singapore and [Zicheng Zhang](https://github.com/zzc-1998)@Shanghai.

